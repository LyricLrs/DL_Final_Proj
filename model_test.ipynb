{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "def build_mlp(layers_dims: List[int]):\n",
    "    layers = []\n",
    "    for i in range(len(layers_dims) - 2):\n",
    "        layers.append(nn.Linear(layers_dims[i], layers_dims[i + 1]))\n",
    "        layers.append(nn.BatchNorm1d(layers_dims[i + 1]))\n",
    "        layers.append(nn.ReLU(True))\n",
    "    layers.append(nn.Linear(layers_dims[-2], layers_dims[-1]))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class MockModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Does nothing. Just for testing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device=\"cuda\", bs=64, n_steps=17, output_dim=256):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.bs = bs\n",
    "        self.n_steps = n_steps\n",
    "        self.repr_dim = 256\n",
    "        \n",
    "        # Encoder with Adaptive Pooling for dynamic image size\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # Outputs [B, C, 1, 1], regardless of input size\n",
    "            nn.Flatten(),\n",
    "            build_mlp([128, 512, self.repr_dim])  # 128 -> 512 -> output_dim\n",
    "        )\n",
    "\n",
    "        # Predictor (GRU) for sequential state prediction\n",
    "        self.predictor = nn.GRU(input_size=self.repr_dim + 2, hidden_size=self.repr_dim, batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self, states, actions):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            states: [B, T, Ch, H, W]\n",
    "            actions: [B, T-1, 2]\n",
    "\n",
    "        Output:\n",
    "            predictions: [B, T, D]\n",
    "        \"\"\"\n",
    "        B, T, C, H, W = states.shape\n",
    "        \n",
    "        # Encode states\n",
    "        encoded_states = self.encoder(states.view(-1, C, H, W)).view(B, T, -1)\n",
    "        \n",
    "        # Pad actions to match T and concatenate with encoded states\n",
    "        actions = F.pad(actions, (0, 0, 1, 0))  # Pad along time dimension\n",
    "        inputs = torch.cat([encoded_states, actions], dim=-1)\n",
    "        \n",
    "        # Predict latent states\n",
    "        predictions, _ = self.predictor(inputs)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class Prober(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding: int,\n",
    "        arch: str,\n",
    "        output_shape: List[int],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_dim = np.prod(output_shape)\n",
    "        self.output_shape = output_shape\n",
    "        self.arch = arch\n",
    "\n",
    "        arch_list = list(map(int, arch.split(\"-\"))) if arch != \"\" else []\n",
    "        f = [embedding] + arch_list + [self.output_dim]\n",
    "        layers = []\n",
    "        for i in range(len(f) - 2):\n",
    "            layers.append(torch.nn.Linear(f[i], f[i + 1]))\n",
    "            layers.append(torch.nn.ReLU(True))\n",
    "        layers.append(torch.nn.Linear(f[-2], f[-1]))\n",
    "        self.prober = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, e):\n",
    "        output = self.prober(e)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from models import MockModel\n",
    "\n",
    "# Custom Dataset Class\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: Path to the dataset directory containing states, actions, and targets.\n",
    "            transform: Optional image transformations for states.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load file paths\n",
    "        self.state_paths = sorted([os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith(\"_state.npy\")])\n",
    "        self.action_paths = sorted([os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith(\"_action.npy\")])\n",
    "        self.target_paths = sorted([os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith(\"_target.npy\")])\n",
    "\n",
    "        assert len(self.state_paths) == len(self.action_paths) == len(self.target_paths), \\\n",
    "            \"Mismatch in number of state, action, and target files.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.state_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        state = np.load(self.state_paths[idx])  # [T, Ch, H, W]\n",
    "        action = np.load(self.action_paths[idx])  # [T-1, 2]\n",
    "        target = np.load(self.target_paths[idx])  # [T, repr_dim]\n",
    "\n",
    "        if self.transform:\n",
    "            state = torch.stack([self.transform(state[i]) for i in range(state.shape[0])])\n",
    "\n",
    "        return torch.tensor(state, dtype=torch.float32), \\\n",
    "               torch.tensor(action, dtype=torch.float32), \\\n",
    "               torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Metrics\n",
    "def compute_accuracy(predictions: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Computes accuracy as a measure of closeness between predictions and targets.\n",
    "    \"\"\"\n",
    "    threshold = 0.1\n",
    "    distances = torch.norm(predictions - targets, dim=-1)\n",
    "    return (distances < threshold).float().mean().item()\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "def train_model(model, train_loader, val_loader, epochs, criterion, optimizer, device):\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss, train_accuracy = 0.0, 0.0\n",
    "        for states, actions, targets in train_loader:\n",
    "            states, actions, targets = states.to(device), actions.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(states, actions)\n",
    "            \n",
    "            # Loss computation\n",
    "            loss = criterion(predictions, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_accuracy += compute_accuracy(predictions, targets)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss, val_accuracy = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for states, actions, targets in val_loader:\n",
    "                states, actions, targets = states.to(device), actions.to(device), targets.to(device)\n",
    "                predictions = model(states, actions)\n",
    "                loss = criterion(predictions, targets)\n",
    "                val_loss += loss.item()\n",
    "                val_accuracy += compute_accuracy(predictions, targets)\n",
    "\n",
    "        # Log epoch metrics\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy / len(train_loader):.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss / len(val_loader):.4f}, Val Accuracy: {val_accuracy / len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Training Script\n",
    "if __name__ == \"__main__\":\n",
    "    # Dataset paths\n",
    "    train_path = \"/scratch/DL24FA/probe_normal/train\"\n",
    "    val_path_normal = \"/scratch/DL24FA/probe_normal/val\"\n",
    "    val_path_wall = \"/scratch/DL24FA/probe_wall/val\"\n",
    "\n",
    "    # Transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Example normalization\n",
    "    ])\n",
    "\n",
    "    # Load datasets\n",
    "    train_dataset = TrajectoryDataset(train_path, transform)\n",
    "    val_dataset_normal = TrajectoryDataset(val_path_normal, transform)\n",
    "    val_dataset_wall = TrajectoryDataset(val_path_wall, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader_normal = DataLoader(val_dataset_normal, batch_size=8, shuffle=False)\n",
    "    val_loader_wall = DataLoader(val_dataset_wall, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = MockModel().to(device)\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    criterion = nn.MSELoss()  # Measure distance in representation space\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Train model\n",
    "    print(\"Training with Normal Validation Set:\")\n",
    "    train_model(model, train_loader, val_loader_normal, epochs=10, criterion=criterion, optimizer=optimizer, device=device)\n",
    "\n",
    "    print(\"\\nEvaluating on Wall Validation Set:\")\n",
    "    train_model(model, train_loader, val_loader_wall, epochs=1, criterion=criterion, optimizer=optimizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
