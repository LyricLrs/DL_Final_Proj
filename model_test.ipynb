{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from resnet import resnet34\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "from dataset import create_wall_dataloader\n",
    "from evaluator import ProbingEvaluator\n",
    "import torch\n",
    "from models import MockModel\n",
    "import glob\n",
    "\n",
    "def build_mlp(layers_dims: List[int]):\n",
    "    layers = []\n",
    "    for i in range(len(layers_dims) - 2):\n",
    "        layers.append(nn.Linear(layers_dims[i], layers_dims[i + 1]))\n",
    "        layers.append(nn.BatchNorm1d(layers_dims[i + 1]))\n",
    "        layers.append(nn.ReLU(True))\n",
    "    layers.append(nn.Linear(layers_dims[-2], layers_dims[-1]))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class VICRegLoss(nn.Module):\n",
    "    def __init__(self, lambda_invariance=25, mu_variance=5, nu_covariance=0.1):\n",
    "        super().__init__()\n",
    "        self.lambda_invariance = lambda_invariance\n",
    "        self.mu_variance = mu_variance\n",
    "        self.nu_covariance = nu_covariance\n",
    "\n",
    "    def forward(self, pred_encs, target_encs):\n",
    "        # Invariance term (MSE)\n",
    "        invariance_loss = F.mse_loss(pred_encs, target_encs)\n",
    "\n",
    "        # Variance term\n",
    "        batch_var_pred = torch.var(pred_encs, dim=0) + 1e-4\n",
    "        batch_var_target = torch.var(target_encs, dim=0) + 1e-4\n",
    "        variance_loss = torch.mean(F.relu(1 - batch_var_pred)) + torch.mean(F.relu(1 - batch_var_target))\n",
    "\n",
    "        # Covariance term\n",
    "        pred_centered = pred_encs - pred_encs.mean(dim=0)\n",
    "        pred_cov = (pred_centered.mT @ pred_centered) / (pred_encs.size(0) - 1)\n",
    "\n",
    "        target_centered = target_encs - target_encs.mean(dim=0)\n",
    "        target_cov = (target_centered.mT @ target_centered) / (target_encs.size(0) - 1)\n",
    "\n",
    "        pred_cov_loss = torch.sum(torch.triu(pred_cov ** 2, diagonal=1)) / pred_encs.size(1)\n",
    "        target_cov_loss = torch.sum(torch.triu(target_cov ** 2, diagonal=1)) / target_encs.size(1)\n",
    "        covariance_loss = pred_cov_loss + target_cov_loss\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = (\n",
    "            self.lambda_invariance * invariance_loss +\n",
    "            self.mu_variance * variance_loss +\n",
    "            self.nu_covariance * covariance_loss\n",
    "        )\n",
    "        return total_loss\n",
    "  \n",
    "class MockModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Does nothing. Just for testing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device=\"cuda\", bs=64, n_steps=17, output_dim=512):\n",
    "        super(MockModel, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.resnet, self.repr_dim = resnet34(num_channels=2, last_activation=\"relu\")\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(self.repr_dim)\n",
    "\n",
    "        self.predictor = nn.GRU(input_size=self.repr_dim + 2, hidden_size=self.repr_dim, batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self, states, actions=None, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            states: [B, T, C, H, W] during training or [B, 1, C, H, W] during inference.\n",
    "            actions: [B, T-1, 2] during training or [B, T-1, 2] during inference (can be None).\n",
    "            train: Boolean flag indicating training or inference mode.\n",
    "\n",
    "        Output:\n",
    "            predictions: [B, T, repr_dim] if train=False\n",
    "                        [B, T, repr_dim] and latent_states [B, T, repr_dim] if train=True\n",
    "        \"\"\"\n",
    "        B, T, C, H, W = states.shape\n",
    "\n",
    "        if train:\n",
    "            # Encode all observations during training\n",
    "            states_flat = states.view(B * T, C, H, W)\n",
    "            encoded_states = self.resnet(states_flat)\n",
    "            latent_states = encoded_states.view(B, T, -1)\n",
    "\n",
    "            # Normalize latent states\n",
    "            latent_states = latent_states.transpose(1, 2)  # [B, T, repr_dim] -> [B, repr_dim, T]\n",
    "            latent_states = self.bn(latent_states).transpose(1, 2)  # [B, repr_dim, T] -> [B, T, repr_dim]\n",
    "\n",
    "            # During training, the model predicts latent states based on the input\n",
    "            predictions = [latent_states[:, 0, :]]  # Start with the first latent state\n",
    "\n",
    "            for t in range(actions.shape[1]):  # Iterate through T-1 actions\n",
    "                action = actions[:, t, :].unsqueeze(1)  # [B, 1, 2]\n",
    "                input_to_predictor = torch.cat([predictions[-1].unsqueeze(1), action], dim=-1)  # [B, 1, repr_dim + 2]\n",
    "                output, _ = self.predictor(input_to_predictor)  # Output: [B, 1, repr_dim]\n",
    "                predictions.append(output.squeeze(1))  # Append [B, repr_dim]\n",
    "\n",
    "            predictions = torch.stack(predictions, dim=1)  # Combine predictions: [B, T, repr_dim]\n",
    "            return predictions, latent_states\n",
    "\n",
    "        else:\n",
    "            init_state = states[:, 0, :, :, :].unsqueeze(1)\n",
    "            encoded_init = self.resnet(init_state.view(B, C, H, W))\n",
    "            latent_states = encoded_init.unsqueeze(1)  # [B, 1, repr_dim]\n",
    "\n",
    "            if actions is None:\n",
    "                return latent_states.squeeze(1)  # [B, repr_dim]\n",
    "\n",
    "            # Normalize latent states\n",
    "            latent_states = latent_states.transpose(1, 2)  # [B, T, repr_dim] -> [B, repr_dim, T]\n",
    "            latent_states = self.bn(latent_states).transpose(1, 2)  # [B, repr_dim, T] -> [B, T, repr_dim]\n",
    "\n",
    "            # During inference, generate predictions autoregressively\n",
    "            predictions = [latent_states[:, 0, :]]  # Start with the first latent state\n",
    "\n",
    "            for t in range(actions.shape[1]):\n",
    "                action = actions[:, t, :].unsqueeze(1)  # [B, 1, 2]\n",
    "                input_to_predictor = torch.cat([predictions[-1].unsqueeze(1), action], dim=-1)  # [B, 1, repr_dim + 2]\n",
    "                output, _ = self.predictor(input_to_predictor)  # Output: [B, 1, repr_dim]\n",
    "                predictions.append(output.squeeze(1))  # Append [B, repr_dim]\n",
    "\n",
    "            predictions = torch.stack(predictions, dim=1)  # Combine predictions: [B, T, repr_dim]\n",
    "\n",
    "            return predictions\n",
    "\n",
    "\n",
    "    def train_model(self, dataset):\n",
    "        \"\"\"\n",
    "        Train the model to align predicted latent representations with target representations.\n",
    "\n",
    "        Args:\n",
    "            dataset: A PyTorch DataLoader containing the training data.\n",
    "        \"\"\"\n",
    "        learning_rate = 0.001 \n",
    "        num_epochs = 100      \n",
    "        device = self.device   \n",
    "        self.train()\n",
    "\n",
    "        # Functions\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "\n",
    "        # Warmup and cosine annealing with restarts\n",
    "        warmup_steps = 10  # Number of warmup epochs\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "        # Modify the learning rate at the beginning of each step\n",
    "        def adjust_learning_rate(optimizer, epoch, warmup_steps, base_lr):\n",
    "            if epoch < warmup_steps:\n",
    "                lr = base_lr * (epoch + 1) / warmup_steps\n",
    "            else:\n",
    "                lr = scheduler.get_lr()[0]\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "        def visualize_latent_states(latent_states, title):\n",
    "            \"\"\"\n",
    "            Visualize latent states using PCA.\n",
    "\n",
    "            Args:\n",
    "                latent_states (torch.Tensor): The latent states tensor of shape [B, T, D].\n",
    "                title (str): Title for the PCA plot.\n",
    "            \"\"\"\n",
    "            latent_states = latent_states.view(-1, latent_states.shape[-1]).cpu().detach().numpy()  # [B * T, D]\n",
    "\n",
    "            print(f\"[Visualize] Final shape for PCA: {latent_states.shape}\")  # Debugging\n",
    "\n",
    "            # Apply PCA to reduce to 2 dimensions\n",
    "            pca = PCA(n_components=2)\n",
    "            latent_2d = pca.fit_transform(latent_states)\n",
    "\n",
    "            # Plot the PCA projections\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(latent_2d[:, 0], latent_2d[:, 1], alpha=0.5, label=\"Latent States\")\n",
    "            plt.title(title)\n",
    "            plt.xlabel(\"PCA Dimension 1\")\n",
    "            plt.ylabel(\"PCA Dimension 2\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            # Save plot as a file\n",
    "            plt.savefig(f\"latent_states_epoch_{title}.png\")  # Adjust filename as needed\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"Starting model training for {num_epochs} epochs with lr={learning_rate}...\")\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=10, delta=1e-4)\n",
    "        epoch_losses = []  # To track losses per epoch\n",
    "        vicreg_loss_fn = VICRegLoss()\n",
    "\n",
    "        for epoch in tqdm(range(num_epochs), desc=\"Model training epochs\"):\n",
    "            batch_losses = []  # Track losses per batch\n",
    "            for batch_idx, batch in enumerate(tqdm(dataset, desc=\"Model training step\")):\n",
    "                states = batch.states.to(device)\n",
    "                actions = batch.actions.to(device)\n",
    "\n",
    "                pred_encs, target_encs = self.forward(states=states, actions=actions, train=True)\n",
    "\n",
    "                # # Visualize latent states every few epochs\n",
    "                latent_flat = pred_encs.view(-1, pred_encs.size(-1)).cpu().numpy()\n",
    "                pca = PCA(n_components=2)\n",
    "                latent_2d = pca.fit_transform(latent_flat)\n",
    "\n",
    "                # Plot\n",
    "                plt.scatter(latent_2d[:, 0], latent_2d[:, 1], alpha=0.5)\n",
    "                plt.title(f\"Epoch {epoch + 1}: Latent Space\")\n",
    "                plt.xlabel(\"PC1\")\n",
    "                plt.ylabel(\"PC2\")\n",
    "                plt.show()\n",
    "\n",
    "                #loss = torch.nn.functional.mse_loss(pred_encs, target_encs)\n",
    "                loss = vicreg_loss_fn(pred_encs, target_encs)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_losses.append(loss.item())  # Append batch loss\n",
    "\n",
    "            avg_epoch_loss = sum(batch_losses) / len(batch_losses)  # Average epoch loss\n",
    "            epoch_losses.append(avg_epoch_loss)\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Avg Loss: {avg_epoch_loss:.8f}\")\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.8f}\")\n",
    "\n",
    "             # Step the scheduler\n",
    "            scheduler.step()\n",
    "\n",
    "            # Check early stopping\n",
    "            early_stopping(avg_epoch_loss)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"Early stopping triggered after epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        print(\"Model training complete.\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait for improvement.\n",
    "            delta (float): Minimum change to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_loss):\n",
    "        # If it's the first epoch or training loss improves\n",
    "        if self.best_loss is None or current_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = current_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True  \n",
    "\n",
    "\n",
    "class Prober(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding: int,\n",
    "        arch: str,\n",
    "        output_shape: List[int],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_dim = np.prod(output_shape)\n",
    "        self.output_shape = output_shape\n",
    "        self.arch = arch\n",
    "\n",
    "        arch_list = list(map(int, arch.split(\"-\"))) if arch != \"\" else []\n",
    "        f = [embedding] + arch_list + [self.output_dim]\n",
    "        layers = []\n",
    "        for i in range(len(f) - 2):\n",
    "            layers.append(torch.nn.Linear(f[i], f[i + 1]))\n",
    "            layers.append(torch.nn.ReLU(True))\n",
    "        layers.append(torch.nn.Linear(f[-2], f[-1]))\n",
    "        self.prober = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, e):\n",
    "        output = self.prober(e)\n",
    "        return output\n",
    "\n",
    "\n",
    "# def test_mock_model():\n",
    "#     # Define test parameters\n",
    "#     batch_size = 64 \n",
    "#     time_steps = 17  # Number of time steps for states\n",
    "#     action_steps = time_steps - 1  # Number of time steps for actions\n",
    "#     channels = 2  # Number of channels in states\n",
    "#     height, width = 65, 65  # Spatial dimensions of states\n",
    "#     action_dim = 2  # Dimensionality of actions\n",
    "#     repr_dim = 256  # Dimensionality of model representation output\n",
    "\n",
    "#     # Generate synthetic test data\n",
    "#     states = torch.randn(batch_size, time_steps, channels, height, width, dtype=torch.float32)  # [B, T, C, H, W]\n",
    "#     actions = torch.randn(batch_size, action_steps, action_dim, dtype=torch.float32)  # [B, T-1, 2]\n",
    "\n",
    "#     # Initialize the model\n",
    "#     model = MockModel(device=\"cpu\", bs=batch_size, n_steps=time_steps, output_dim=repr_dim)\n",
    "\n",
    "#     # Pass data through the model\n",
    "#     predictions = model(states, actions)\n",
    "\n",
    "#     # Print input and output shapes to validate\n",
    "#     print(f\"States shape: {states.shape}\")  # Expected: [B, T, C, H, W]\n",
    "#     print(f\"Actions shape: {actions.shape}\")  # Expected: [B, T-1, 2]\n",
    "#     print(f\"Predictions shape: {predictions.shape}\")  # Expected: [B, T, repr_dim]\n",
    "\n",
    "#     # Validate output shape\n",
    "#     assert predictions.shape == (batch_size, time_steps, repr_dim), \\\n",
    "#         f\"Output shape mismatch: expected {(batch_size, time_steps, repr_dim)}, got {predictions.shape}\"\n",
    "#     print(\"Model handled data correctly!\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test_mock_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Check for GPU availability.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    return device\n",
    "\n",
    "\n",
    "def load_data(device):\n",
    "    data_path = \"/scratch/DL24FA\"\n",
    "\n",
    "    probe_train_ds = create_wall_dataloader(\n",
    "        data_path=f\"{data_path}/probe_normal/train\",\n",
    "        probing=True,\n",
    "        device=device,\n",
    "        train=True,\n",
    "    )\n",
    "\n",
    "    probe_val_normal_ds = create_wall_dataloader(\n",
    "        data_path=f\"{data_path}/probe_normal/val\",\n",
    "        probing=True,\n",
    "        device=device,\n",
    "        train=False,\n",
    "    )\n",
    "\n",
    "    probe_val_wall_ds = create_wall_dataloader(\n",
    "        data_path=f\"{data_path}/probe_wall/val\",\n",
    "        probing=True,\n",
    "        device=device,\n",
    "        train=False,\n",
    "    )\n",
    "\n",
    "    probe_val_ds = {\"normal\": probe_val_normal_ds, \"wall\": probe_val_wall_ds}\n",
    "\n",
    "    return probe_train_ds, probe_val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MockModel(device=\"cuda\").to(\"cuda\")\n",
    "probe_train_ds, probe_val_ds = load_data(device=\"cuda\")\n",
    "model.train_model(dataset=probe_train_ds)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
